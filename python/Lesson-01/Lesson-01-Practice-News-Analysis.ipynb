{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 课后练习：新闻热词分析与关联任务分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们每天接受到的文字信息中，新闻内容占据了相当的部分。在此次的课程联系中，我们会带着大家完成一个新闻热词的分析与关联人物的分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "经过本次的训练，大家能掌握的能力有：\n",
    "\n",
    "1. 文件读取的方法；\n",
    "2. tf-idf重点单词提取的方法；\n",
    "3. collection Counter的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 你在这次训练中，做什么？  \n",
    "\n",
    "1. 把这个notebook中的所有代码自己手敲一遍；\n",
    "2. 解答notebook中预留的问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/timg.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 文件的读取与分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们的此次使用的文件，存放在 \"datas/articles_9k\"中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use `open()` to get the content from a file\n",
    "content = open('dataset/article_9k.txt', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARACTERS = content.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33425826"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHARACTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们可以看到，一共有3千多万个字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 切割成句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体验版内测稳定版暂不受影响以确保工程师可以集中全部精力进行系统优化工作有人猜测这也是将精力主要用到MIUI9的研发之中MI'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHARACTERS[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看出来，这些都是一个一个单字组成的，如果我们要进行文章内容的分析，我们要把这些连起来的单子，切割成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体验版内测稳定版暂不受影响以确保工程师可以集中全部精力进行系统优化工作有人猜测这也是将精力主要用到MIUI9的研发之中MIUI8去年5月发布距今已有一年有余也是时候更新换代了当然关于MIUI9的确切信息我们还是等待官方消息\\n骁龙835作为唯一通过Windows10桌面平台认证的ARM处理器高通强调不会因为只考虑性能而去屏蔽掉小核心相反他们正联手微软找到一种适合桌面平台的兼顾性能和功耗的完美方案报道称微软已经拿到了一些新的源码以便Windows10更好地理解biglittle架构资料显示骁龙835作为一款集成了CPUGPU基带蓝牙WiFi的SoC比传统的Wintel方案可以节省至少30的PCB空间按计划今年Q4华硕惠普联想将首发骁龙835Win10电脑预计均是二合一形态的产品当然高通骁龙只是个开始未来也许还能见到三星Exynos联发科华为麒麟小米澎湃等进入Windows10桌面平台\\n此前的一加3T搭载的是3400mAh电池DashCharge快充规格为5V4A至于电池缩水可能与刘作虎所说一加手机5要做市面最轻薄大屏旗舰的设定有关按照目前掌握的资料一加手机5拥有55寸1080P三星AMOLED显示屏6G8GBRAM64GB128GBROM双1600万摄像头备货量惊喜根据京东泄露的信息一加5起售价是xx99元应该是在279928992999中的某个\\n这是6月18日在葡萄牙中部大佩德罗冈地区拍摄的被森林大火烧毁的汽车新华社记者张立云摄\\n原标题44岁女子跑深圳约会网友被拒暴雨中裸身奔走深圳交警微博称昨日清晨交警发现有一女子赤裸上身行走在南坪快速上期间还起了轻生年头一辅警发现后赶紧为其披上黄衣并一路劝说她那么事发时到底都发生了些什么呢南都记者带您一起还原现场南都记者在龙岗大队坂田中队见到了辅警刘青发现女生的辅警一位外表高大帅气说话略带些腼腆的90后青年刘青介绍6月16日早上7时36分他正在环城南路附近值勤接到中队关于一位女子裸身进入机动车可能有危险的警情随后骑着小铁骑开始沿路寻找大概花了十多分钟在南坪大道坂田出口往龙岗方向的逆行辅道上发现该女子女子身上一丝不挂地逆车流而行时走时停时坐时躺险象环生刘青停好小铁骑和另外一名巡防员追了上去发现女子的情绪很低落话不多刘青尝试和女子交流劝说女子离开可女子并不愿意'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHARACTERS[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在编程语言中，'\\n'是一个特殊字符，表示一个句子的换行。那么我们可以使用这个特殊标志来对文章进行切词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = CHARACTERS.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思考：为什么sentences用的是复数的形式？为什么CHARACTERS用的是全部大写的形式？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89612"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 思考：这个89612意味着什么？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体验版内测稳定版暂不受影响以确保工程师可以集中全部精力进行系统优化工作有人猜测这也是将精力主要用到MIUI9的研发之中MIUI8去年5月发布距今已有一年有余也是时候更新换代了当然关于MIUI9的确切信息我们还是等待官方消息'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'图片来自于Flickr亚马逊以竞争性的价格著称它正试图通过发力食品杂货领域吸引更多的中低收入消费者据悉亚马逊已经向接受政府救助的用户提供Prime会员资格折扣同时还参与了向食品券使用者派发食品杂货的试点项目实际上全食超市已经推行降价以试图扭转其1992年上市以来最严重的销量下滑它拥有四家全食365超市其造价和运营比传统全食超市成本更低同时还针对年轻用户提供价格更低的商品亚马逊曾在其西雅图AmazonGo实体店开发出无需排队结账的技术据知情人士称亚马逊正考虑利用该技术扩大成本消减举措这项技术无需出纳员或结账处用户只需智能手机即可支付费用这将帮助亚马逊与其他实体商店区分开来并降低全食超市的劳工成本知情人士称留下来的员工将帮助提升用户的购物体验针对报道一位亚马逊发言人表示该公司并没有将全食超市出纳工作自动化的计划同时也没有裁员计划知情人士表示亚马逊还希望改变全食超市的库存推出自有品牌产品来取代售价过高的产品从而吸引大众这与全食超市利用自有品牌进行价格竞争的举措相符这些改变可能需要长期才能实现而由于收购全食超市的交易预计直到下半年才能完成亚马逊拥有大量的时间来改变战略'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[199]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们可以看到，文章被分成了一个一个的句子，那么，我们现在进行第一个任务，找到每个句子中的关键词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为了切词，我们需要使用jieba这个工具包进行分词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\geesi\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.805 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['我', '今天', '不', '知道', '为什么', '迟到', '了']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(jieba.cut('我今天不知道为什么迟到了'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string):\n",
    "    return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentences_with_cut_tokens = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 需要你进行的第1个任务：完成all_sentences_with_cut_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个任务中，我们需要构建 all_sentence_with_cut_tokens, 该元素为一个列表，列表中的每个元素也是一个列表，这个列表中包含的是一个一个单独的词汇。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#you can code here\n",
    "all_sentences_with_cut_tokens = [cut(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了检验你的程序是否正确，请运行以下代码，如果你的代码是正确的，会打印“你做对了”，否则，你报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你做对了\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(all_sentences_with_cut_tokens, list)\n",
    "assert isinstance(all_sentences_with_cut_tokens[0], list)\n",
    "assert isinstance(all_sentences_with_cut_tokens[0][0], str)\n",
    "assert all_sentences_with_cut_tokens[0][0] == '此外'\n",
    "print('你做对了')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务2：计算每个句子中，每个单词的tf值和idf值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所谓，tf值，全称是 “term frequency”，指的是某个单词在一个句子中出现的次数\n",
    "\n",
    "所谓，df值，全称是 \"document frequency\"， 指的是一个单词出现在了多少个文章中\n",
    "\n",
    "而 tf-idf中的“i”，是 inverse的意思，值得是用 df的倒数。\n",
    "\n",
    "> \n",
    "\n",
    "为了保持数据的单位的稳定，我们常常会给idf加上一个log函数，tfidf值就等于 $ tf * \\frac{1}{log(idf)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是为什么呢？ 例如“的”这个单词，在某个文章或者句子中出现的次数很多，但是它在每个文章中几乎都出现了，那么，这个单词就不是很重要的词汇，但是如果某个单词的'tf'值很大，但是'df'值很小，那么 'tf*1/idf' 这个值也会很大，这种在一个文章中出现了很多次，但是别的文章中都没有出现的单词，我们就说这种单词是重要单词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(word, all_sentences):\n",
    "    return np.log10(len(all_sentences) / sum(1 for s in all_sentences if word in s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10515145796604719"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf('的', sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0544093602001214"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf('我们', sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(word, sentence_cut):\n",
    "    return sentence_cut.count(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外',\n",
       " '自',\n",
       " '本周',\n",
       " '6',\n",
       " '月',\n",
       " '12',\n",
       " '日起',\n",
       " '除',\n",
       " '小米',\n",
       " '手机',\n",
       " '6',\n",
       " '等',\n",
       " '15',\n",
       " '款',\n",
       " '机型',\n",
       " '外',\n",
       " '其余',\n",
       " '机型',\n",
       " '已',\n",
       " '暂停',\n",
       " '更新',\n",
       " '发布',\n",
       " '含',\n",
       " '开发',\n",
       " '版',\n",
       " '体验版',\n",
       " '内测',\n",
       " '稳定版',\n",
       " '暂不受',\n",
       " '影响',\n",
       " '以',\n",
       " '确保',\n",
       " '工程师',\n",
       " '可以',\n",
       " '集中',\n",
       " '全部',\n",
       " '精力',\n",
       " '进行',\n",
       " '系统优化',\n",
       " '工作',\n",
       " '有人',\n",
       " '猜测',\n",
       " '这',\n",
       " '也',\n",
       " '是',\n",
       " '将',\n",
       " '精力',\n",
       " '主要',\n",
       " '用到',\n",
       " 'MIUI9',\n",
       " '的',\n",
       " '研发',\n",
       " '之中',\n",
       " 'MIUI8',\n",
       " '去年',\n",
       " '5',\n",
       " '月',\n",
       " '发布',\n",
       " '距今已有',\n",
       " '一年',\n",
       " '有余',\n",
       " '也',\n",
       " '是',\n",
       " '时候',\n",
       " '更新换代',\n",
       " '了',\n",
       " '当然',\n",
       " '关于',\n",
       " 'MIUI9',\n",
       " '的',\n",
       " '确切',\n",
       " '信息',\n",
       " '我们',\n",
       " '还是',\n",
       " '等待',\n",
       " '官方消息']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences_with_cut_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf('小米', all_sentences_with_cut_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 我们可以看到，tf的值往往比idf大很多，这会造成tf的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么，我们就可以构造一个函数，这个函数输入一个单词和一个句子，然后输出是这个单词对应的tf-idf值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(word, sentence_cut, all_sentence):\n",
    "    return tf(word, sentence_cut) * idf(word, all_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21030291593209438"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('的', all_sentences_with_cut_tokens[0], sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.943765998445156"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('小米', all_sentences_with_cut_tokens[0], sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.790922637741201"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf('机型', all_sentences_with_cut_tokens[0], sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上3个数值的意思是，在这个文章中，“机型”的重要性大于“小米”，大于“的”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务2： 输入一个句子，获得句子中每个单词的tfidf值\n",
    "\n",
    "### 这个场景下，1. 你需要Python的dictionary这个数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "# the use of dictionary\n",
    "student_age_info = dict()\n",
    "\n",
    "student_age_info['小明'] = 10\n",
    "student_age_info['小明'] += 1\n",
    "\n",
    "print(student_age_info['小明'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二，你需要Python的set()函数，将一个列表转换成一个集合，集合相对于list，特点是，每个元素只会出现一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_list = [1, 2, 3, 1, 1, 3,1, 1, 41, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 41}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(some_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_from_sentence(sentence_cut, all_sentences):\n",
    "    return {word:tfidf(word, sentence_cut, all_sentences) for word in sentence_cut}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你的程序正确，那么运行以下代码应该打印“你做对了！”，否则将会打印出错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你做对了！\n"
     ]
    }
   ],
   "source": [
    "assert '确切' in get_tfidf_from_sentence(all_sentences_with_cut_tokens[0], sentences)\n",
    "assert isinstance(get_tfidf_from_sentence(all_sentences_with_cut_tokens[0], sentences), dict)\n",
    "assert isinstance(get_tfidf_from_sentence(all_sentences_with_cut_tokens[0], sentences)['确切'], float)\n",
    "\n",
    "print(\"你做对了！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3, 使用python内置的sorted方法对结果进行排序，找到最重要的单词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorted是一个很常用的方法，用法很简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_list = [1, 2, 3, 4, 1, 3, 1, 41, 1, 1, 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 2, 3, 3, 4, 31, 41]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(some_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41, 31, 4, 3, 3, 2, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(some_list, reverse=True) #加上参数，可以逆序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于我们这个问题而言，我们想做的是，通过每个单词的“值”来排序"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们来直接sorted我们的之前get_tfidf函数产出的dictionary，结果会是什么呢？ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1_result = get_tfidf_from_sentence(all_sentences_with_cut_tokens[0], sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12',\n",
       " '15',\n",
       " '5',\n",
       " '6',\n",
       " 'MIUI8',\n",
       " 'MIUI9',\n",
       " '一年',\n",
       " '主要',\n",
       " '之中',\n",
       " '也',\n",
       " '了',\n",
       " '以',\n",
       " '体验版',\n",
       " '信息',\n",
       " '全部',\n",
       " '关于',\n",
       " '其余',\n",
       " '内测',\n",
       " '去年',\n",
       " '发布',\n",
       " '可以',\n",
       " '含',\n",
       " '外',\n",
       " '官方消息',\n",
       " '将',\n",
       " '小米',\n",
       " '工作',\n",
       " '工程师',\n",
       " '已',\n",
       " '开发',\n",
       " '当然',\n",
       " '影响',\n",
       " '我们',\n",
       " '手机',\n",
       " '日起',\n",
       " '时候',\n",
       " '是',\n",
       " '暂不受',\n",
       " '暂停',\n",
       " '更新',\n",
       " '更新换代',\n",
       " '月',\n",
       " '有人',\n",
       " '有余',\n",
       " '本周',\n",
       " '机型',\n",
       " '款',\n",
       " '此外',\n",
       " '版',\n",
       " '猜测',\n",
       " '用到',\n",
       " '的',\n",
       " '研发',\n",
       " '确保',\n",
       " '确切',\n",
       " '稳定版',\n",
       " '等',\n",
       " '等待',\n",
       " '精力',\n",
       " '系统优化',\n",
       " '自',\n",
       " '距今已有',\n",
       " '还是',\n",
       " '这',\n",
       " '进行',\n",
       " '除',\n",
       " '集中']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(sentence_1_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你会发现这个结果是根据字符排序的，不是我们想要的结果。我们还可以做个测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_info = {\n",
    "    'A': 9,\n",
    "    'B': 4,\n",
    "    'Z': 8,\n",
    "    'D': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'D', 'Z']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(student_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么这个时候怎么办呢？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们需要用到一个sorted的参数，这个参数叫做`key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('D', 1), ('B', 4), ('Z', 8), ('A', 9)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(student_info.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 你会发现，这个按照studen_info的key值进行排序了，如果要从大到小也很简单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 9), ('Z', 8), ('B', 4), ('D', 1)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(student_info.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这个里边，有几个点你可能目前还不知道，一个是 .items() 是用来做什么的，一个是 lambda是用来做什么的。如果你不知道的话，也没关系，先用！这个涉及到的知识，之后的课程会涉及到。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task3: 构建一个函数，输入一个切词切好的句子，然后返回tfidf值大小排前25%的单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_tfidf(sentence_cut, all_sentences):\n",
    "    \"\"\"\n",
    "    return : [(word1, tfidf_value), (word2, tfidf_value)]\n",
    "    \"\"\"\n",
    "    word2tfidf = sorted(get_tfidf_from_sentence(sentence_cut, all_sentences).items(), \n",
    "                        key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return word2tfidf[:int(len(sentence_cut) * 0.25)]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MIUI9', 9.904732340414148),\n",
       " ('机型', 5.790922637741201),\n",
       " ('体验版', 4.952366170207074),\n",
       " ('稳定版', 4.952366170207074),\n",
       " ('系统优化', 4.952366170207074),\n",
       " ('MIUI8', 4.952366170207074),\n",
       " ('精力', 4.862456173006074),\n",
       " ('暂不受', 4.350306178879111),\n",
       " ('官方消息', 3.9523661702070734),\n",
       " ('内测', 3.9109734850488485),\n",
       " ('距今已有', 3.6301468754731543),\n",
       " ('更新换代', 3.433852230329186),\n",
       " ('确切', 3.1394528135642177),\n",
       " ('有余', 2.9611400945145787),\n",
       " ('小米', 2.943765998445156),\n",
       " ('用到', 2.709328121520779),\n",
       " ('猜测', 2.6828532259891573),\n",
       " ('其余', 2.2953103173499696),\n",
       " ('工程师', 2.2586392212834263)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_tfidf(all_sentences_with_cut_tokens[0], sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这些单词是不是这个句子的重点单词呢？ ：）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 人物信息关联分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了分析热词，我们还想对人物之间的关联关系进行分析，我们想知道那些名字同时出现的次数比较多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要判断人的名字，这件事情之前是很复杂的，现在，jieba有一个很方便的工具，可以来判断一个单词是不是人名，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = '张晓竞是此次的最佳选手'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jieba import posseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pair('张晓竞', 'nr'),\n",
       " pair('是', 'v'),\n",
       " pair('此次', 'r'),\n",
       " pair('的', 'uj'),\n",
       " pair('最佳', 'z'),\n",
       " pair('选手', 'v')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(posseg.cut(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 所有写的是\"nr\"的单词，都是人名"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_name(cut_word):\n",
    "    w, _type = list(posseg.cut(cut_word))[0]\n",
    "    \n",
    "    if _type == 'nr': return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_name('周杰伦')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_name('周杰')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_name('伊丽莎白')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_name('小猫')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么，我们可以构建一个函数，这个函数我们输入一个切词之后的句子，返回一个 list， 这个list包含了文章中所有包含的人名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names_from_sentence(cut_sentence):\n",
    "    return [w for w in cut_sentence if is_name(w)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['普惠性', '任远明', '邹', '普惠性']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_names_from_sentence(all_sentences_with_cut_tokens[99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['阿森纳',\n",
       " '桑切斯',\n",
       " '阿森纳',\n",
       " '桑切斯',\n",
       " '仁和',\n",
       " '桑切斯',\n",
       " '桑切斯',\n",
       " '阿森纳',\n",
       " '桑切斯',\n",
       " '桑切斯',\n",
       " '拜仁',\n",
       " '拜仁',\n",
       " '拜仁',\n",
       " '阿森纳',\n",
       " '桑切斯',\n",
       " '拜仁',\n",
       " '桑切斯',\n",
       " '桑切斯',\n",
       " '拜仁',\n",
       " '拜仁',\n",
       " '周薪',\n",
       " '拜仁',\n",
       " '拜仁',\n",
       " '桑切斯',\n",
       " '拜仁',\n",
       " '高薪',\n",
       " '拜仁',\n",
       " '阿森纳',\n",
       " '马尔科']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_names_from_sentence(all_sentences_with_cut_tokens[200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 思考题：如何把所有的句子运行一遍， 生成一个字典，这个字典中的每个key是人名，N1, value是一个dictionary，这个dictionary中，每个的key是一个人名，Ni, value是Ni与N1同时出现在一篇文章中的次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_correlate(sentences_cut):\n",
    "    \"\"\"\n",
    "    \n",
    "    return : {\n",
    "    \n",
    "        name1: {\n",
    "            name1_1: int\n",
    "            name1_2: int\n",
    "        }\n",
    "        \n",
    "        name2: {\n",
    "            name2_1: int\n",
    "            name2_2: int\n",
    "        }\n",
    "    \n",
    "    }\n",
    "    \n",
    "    \"\"\"\n",
    "    sentences_names = [get_names_from_sentence(sentence) for sentence in sentences_cut]\n",
    "    name2sentence = dict()\n",
    "    for i, names in  enumerate(sentences_names):\n",
    "        for name in names:\n",
    "            if not (name in name2sentence):\n",
    "                name2sentence[name] = set([i])\n",
    "            else:\n",
    "                name2sentence[name].add(i)\n",
    "    \n",
    "    all_names = list(name2sentence.keys())\n",
    "    name2name = {name:dict() for name in all_names}\n",
    "    for index, name in enumerate(all_names[:-1]):\n",
    "        for cor_name in all_names[index + 1:]:\n",
    "            cor_count = len(name2sentence[name].intersection(name2sentence[cor_name]))\n",
    "            if cor_count > 0:\n",
    "                name2name[name][cor_name] = cor_count\n",
    "                name2name[cor_name][name] = cor_count\n",
    "    \n",
    "#     return [name2sentence, name2name]\n",
    "    return name2name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 如果你的程序正确，那么以下代码可以运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample_corrleate = get_name_correlate(all_sentences_with_cut_tokens[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'张立': 2}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_corrleate['佩德罗']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'史': 1,\n",
       " '胡': 1,\n",
       " '封锁': 1,\n",
       " '李俊': 1,\n",
       " '蔡': 1,\n",
       " '张迪': 1,\n",
       " '清德': 1,\n",
       " '峰': 1,\n",
       " '高中历史': 1,\n",
       " '明文': 1,\n",
       " '许智杰': 1,\n",
       " '罗致': 1,\n",
       " '柯建铭': 1,\n",
       " '陆客': 1,\n",
       " '陈菊': 1}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_corrleate['李显龙']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 以上的数据分析结果，会有一些小问题，但是瑕不掩瑜，我们之后再学习一点数据图标的方法，就可以很好的展示我们的结果了，可以是词云的方式，也可以是连接图的方式。大家一定要相信，那些酷炫的可视化效果不是技术难点，重点是后边的编程实现和算法模型。你体会到了吗？ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
